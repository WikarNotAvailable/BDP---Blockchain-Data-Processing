# BDP-Blockchain-Data-Processing
University group project, which main goals are to extract, store and process blockchain big data with cloud computing in order to detect anomalies using machine learning and statistic methods.

Creating datasets for local testing

ETL - run perform_etl.py and perform_benchmark_etl.py in etl folder

Aggregations - run aggregate.py and aggregate_benchmark in aggregate folder 

Preprocessing (preprocessing folder in anomalies_detection folder):

a) For benchmark data run preprocess_benchmark_datasets.py (once)

b) For training data run preporcess_training_datasets.py (3 times, change step from 1-3 every time):

![image](https://github.com/user-attachments/assets/1eda202e-a3c9-4c7f-9f3f-047b5dddd79f)
